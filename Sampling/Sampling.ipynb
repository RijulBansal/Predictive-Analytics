{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Sampling_DataSet'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 13 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (13/13), 466.53 KiB | 715.00 KiB/s, done.\n",
      "Resolving deltas: 100% (2/2), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/AnjulaMehto/Sampling_DataSet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time        V1        V2        V3        V4        V5        V6  \\\n",
      "545   409 -0.544922  0.595407  1.813261 -1.344670  0.016864 -0.601398   \n",
      "679   513  1.255258  0.075190  0.225733  0.881766  0.154508  0.631960   \n",
      "400   290 -0.695818  0.581773  2.378180  0.063396  0.329119 -0.449865   \n",
      "14     12 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
      "548   410 -1.086133 -0.704548  2.329021 -0.885715  0.617677  0.478894   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "545  0.660876 -0.058978  0.317033  ... -0.123048 -0.148228 -0.076075   \n",
      "679 -0.385968  0.189493  0.447980  ...  0.088457  0.321206 -0.235167   \n",
      "400  1.269104 -0.758363  0.381712  ... -0.327948 -0.369683 -0.426987   \n",
      "14  -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586   \n",
      "548 -0.267414  0.354042  0.558999  ...  0.021119  0.213192  0.186858   \n",
      "\n",
      "          V24       V25       V26       V27       V28  Amount  Class  \n",
      "545  0.074036 -0.486633  0.724549  0.104294 -0.055110    0.77      0  \n",
      "679 -1.325033  0.643129 -0.133690  0.053069  0.012484    7.00      0  \n",
      "400  0.420170  0.235207  0.194957 -0.708471 -0.621219   30.50      0  \n",
      "14   0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n",
      "548 -0.207543 -0.701080  0.737603 -0.093269 -0.085372   39.77      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv(\"Sampling_DataSet/Creditcard_data.csv\")\n",
    "\n",
    "sample_size = 5\n",
    "\n",
    "random_sample = df.sample(n=sample_size, random_state=0)\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "27     23  1.322707 -0.174041  0.434555  0.576038 -0.836758 -0.831083   \n",
      "54     37  1.295668  0.341483  0.081505  0.566746 -0.110459 -0.766325   \n",
      "81     52  1.147369  0.059035  0.263632  1.211023 -0.044096  0.301067   \n",
      "108    73  1.162281  1.248178 -1.581317  1.475024  1.138357 -1.020373   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
      "27  -0.264905 -0.220982 -1.071425  ... -0.284376 -0.323357 -0.037710   \n",
      "54   0.073155 -0.168304  0.071837  ... -0.323607 -0.929781  0.063809   \n",
      "81  -0.132960  0.227885  0.252191  ... -0.087813 -0.110756 -0.097771   \n",
      "108  0.638387 -0.136762 -0.805505  ... -0.124012 -0.227150 -0.199185   \n",
      "\n",
      "          V24       V25       V26       V27       V28  Amount  Class  \n",
      "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "27   0.347151  0.559639 -0.280158  0.042335  0.028822   16.00      0  \n",
      "54  -0.193565  0.287574  0.127881 -0.023731  0.025200    0.99      0  \n",
      "81  -0.323374  0.633279 -0.305328  0.027394 -0.000580    6.67      0  \n",
      "108 -0.289757  0.776244 -0.283950  0.056747  0.084706    1.00      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv(\"Sampling_DataSet/Creditcard_data.csv\")\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "k = int(math.sqrt(n))\n",
    "\n",
    "sample = df.iloc[::k]\n",
    "\n",
    "print(sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/var/folders/ym/p17r5n7j7w34lb9ys97qzzw40000gn/T/ipykernel_31495/2477991772.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/Users/adityapandey/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model   Sampling  Accuracy\n",
      "0     M1  Sampling1  0.956897\n",
      "1     M2  Sampling1  0.956897\n",
      "2     M3  Sampling1  0.987069\n",
      "3     M4  Sampling1  0.844828\n",
      "4     M5  Sampling1  0.935345\n",
      "5     M1  Sampling2  0.810345\n",
      "6     M2  Sampling2  0.810345\n",
      "7     M3  Sampling2  0.780172\n",
      "8     M4  Sampling2  0.568966\n",
      "9     M5  Sampling2  0.375000\n",
      "10    M1  Sampling3  0.987069\n",
      "11    M2  Sampling3  0.952586\n",
      "12    M3  Sampling3  0.987069\n",
      "13    M4  Sampling3  0.823276\n",
      "14    M5  Sampling3  0.935345\n",
      "15    M1  Sampling4  0.413793\n",
      "16    M2  Sampling4  0.474138\n",
      "17    M3  Sampling4  0.077586\n",
      "18    M4  Sampling4  0.534483\n",
      "19    M5  Sampling4  0.534483\n",
      "20    M1  Sampling5  0.961207\n",
      "21    M2  Sampling5  0.952586\n",
      "22    M3  Sampling5  0.982759\n",
      "23    M4  Sampling5  0.814655\n",
      "24    M5  Sampling5  0.918103\n",
      "\n",
      "Best Sampling Technique for Each Model:\n",
      "   Model   Sampling  Accuracy\n",
      "10    M1  Sampling3  0.987069\n",
      "1     M2  Sampling1  0.956897\n",
      "2     M3  Sampling1  0.987069\n",
      "3     M4  Sampling1  0.844828\n",
      "4     M5  Sampling1  0.935345\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "df = pd.read_csv('Sampling_DataSet/Creditcard_data.csv')\n",
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "samplers = {\n",
    "    'Sampling1': SMOTE(),\n",
    "    'Sampling2': RandomUnderSampler(),\n",
    "    'Sampling3': RandomOverSampler(),\n",
    "    'Sampling4': NearMiss(),\n",
    "    'Sampling5': SMOTEENN()\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'M1': AdaBoostClassifier(),\n",
    "    'M2': DecisionTreeClassifier(),\n",
    "    'M3': ExtraTreesClassifier(),\n",
    "    'M4': LinearDiscriminantAnalysis(),\n",
    "    'M5': GaussianProcessClassifier()\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Sampling\", \"Accuracy\"])\n",
    "\n",
    "for sampling_name, sampler in samplers.items():\n",
    "    X_sampled, y_sampled = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_sampled, y_sampled)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        new_row = pd.DataFrame([{\"Model\": model_name, \"Sampling\": sampling_name, \"Accuracy\": acc}])\n",
    "        results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "best_sampling_technique = results.loc[results.groupby(\"Model\")[\"Accuracy\"].idxmax()]\n",
    "\n",
    "print(\"\\nBest Sampling Technique for Each Model:\")\n",
    "print(best_sampling_technique)\n",
    "\n",
    "results.to_csv('sampling_results.csv', index=False)\n",
    "best_sampling_technique.to_csv('best_sampling_techniques.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
